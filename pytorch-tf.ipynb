{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.squeezenet1_1(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_lookups = {}\n",
    "\n",
    "def conv2d(c,**kwargs):\n",
    "    padding = 'VALID' if c.padding[0] is 0 else 'SAME'\n",
    "    #print(c,padding)\n",
    "    filters = c.out_channels\n",
    "    size = c.kernel_size\n",
    "    parameters = [p for p in c.parameters()]\n",
    "    W = parameters[0].data.numpy()\n",
    "    if len(parameters) > 1:\n",
    "        b = parameters[1].data.numpy()\n",
    "    #print(W.shape,)\n",
    "\n",
    "    W = np.transpose(W,[2,3,1,0])\n",
    "    #print(W.shape)\n",
    "\n",
    "    with tf.variable_scope(\"conv\"):\n",
    "        wi = tf.constant_initializer(W)\n",
    "        if len(parameters) > 1:\n",
    "            bi = tf.constant_initializer(b)\n",
    "        W = tf.get_variable('weights',shape=W.shape,initializer=wi)#,\n",
    "        if len(parameters) > 1:\n",
    "            b = tf.get_variable('bias',shape=b.shape,initializer=bi)#,\n",
    "    x = tf.nn.conv2d(kwargs['inp'],W,[1,c.stride[0],c.stride[1],1],padding)\n",
    "    if len(parameters) > 1:\n",
    "        x = tf.nn.bias_add(x,b)\n",
    "    #print('conv ', x.get_shape())\n",
    "    return x\n",
    "\n",
    "def relu(c,**kwargs):\n",
    "    return tf.nn.relu(kwargs['inp'])\n",
    "def max_pool(c,**kwargs):\n",
    "    padding = 'VALID' if c.padding is 0 else 'SAME'\n",
    "    x = tf.nn.max_pool(kwargs['inp'],[1,c.kernel_size,c.kernel_size,1],strides=[1,c.stride,c.stride,1],padding=padding)\n",
    "    #print('max ', x.get_shape())\n",
    "    return x\n",
    "def avg_pool(c,**kwargs):\n",
    "    padding = 'VALID' if c.padding is 0 else 'SAME'\n",
    "    x = tf.nn.avg_pool(kwargs['inp'],[1,c.kernel_size,c.kernel_size,1],strides=[1,c.stride,c.stride,1],padding=padding)\n",
    "    return x\n",
    "def dropout(c,**kwargs):\n",
    "    #print('dropout')\n",
    "    return kwargs['inp']\n",
    "def fire_module(c,**kwargs):\n",
    "    # couldn't figure out how to\n",
    "    # automatically unravel it\n",
    "    with tf.variable_scope(\"fire\"):\n",
    "        with tf.variable_scope(\"squeeze\"):\n",
    "            s = conv2d(c.squeeze,inp=kwargs['inp'])\n",
    "            s = tf.nn.relu(s)\n",
    "        with tf.variable_scope(\"e11\"):\n",
    "            e11 = conv2d(c.expand1x1,inp=s)\n",
    "            e11 = tf.nn.relu(e11)\n",
    "        with tf.variable_scope(\"e33\"):\n",
    "            e33 = conv2d(c.expand3x3,inp=s)\n",
    "            e33 = tf.nn.relu(e33)\n",
    "    x = tf.concat([e11,e33],3)\n",
    "    #print('fire ',x.get_shape())\n",
    "    return x\n",
    "\n",
    "def seq_container(c,**kwargs):\n",
    "    x = kwargs['inp']\n",
    "    for c2 in enumerate(c.children()):\n",
    "        c2_class = c2[1].__class__\n",
    "        if c2_class in type_lookups:\n",
    "            with tf.variable_scope('layer' + str(c2[0])):\n",
    "                x = type_lookups[c2_class](c2[1],inp = x)\n",
    "        else:\n",
    "            unknown_class(c2[1])\n",
    "            print(c2_class)\n",
    "    return x\n",
    "def batch_norm(c,**kwargs):\n",
    "    print('batch_norm')\n",
    "    return kwargs['inp']\n",
    "type_lookups[torch.nn.modules.conv.Conv2d] = conv2d\n",
    "type_lookups[torch.nn.modules.activation.ReLU] = relu\n",
    "type_lookups[torch.nn.modules.container.Sequential] = seq_container\n",
    "type_lookups[torch.nn.modules.pooling.MaxPool2d] = max_pool\n",
    "type_lookups[torch.nn.modules.pooling.AvgPool2d] = avg_pool\n",
    "type_lookups[torch.nn.modules.dropout.Dropout] = dropout\n",
    "type_lookups[torchvision.models.squeezenet.Fire] = fire_module\n",
    "type_lookups[torch.nn.modules.batchnorm.BatchNorm2d] = batch_norm\n",
    "tf.reset_default_graph()\n",
    "input_image = tf.placeholder('float',shape=[None,224,224,3])\n",
    "if len([_ for _ in model.children()]) == 2:\n",
    "    for idx,c in enumerate(model.children()):\n",
    "        if idx is 0:\n",
    "            with tf.variable_scope('features'):\n",
    "                features = type_lookups[c.__class__](c,inp=input_image)\n",
    "        elif idx is 1:\n",
    "            with tf.variable_scope('classifier'):\n",
    "                classifier = type_lookups[c.__class__](c,inp=features)\n",
    "                classifier = tf.reshape(classifier,[-1,1000])\n",
    "else:\n",
    "    x = input_image\n",
    "    for idx,c in enumerate(model.children()):\n",
    "        x = type_lookups[c.__class__](c,inp=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy.misc import imresize\n",
    "import os\n",
    "\n",
    "with open('labels.txt') as fp:\n",
    "    labels = [c[:-2].split(':')[1] for c in fp.readlines()]\n",
    "def get_img(filename):\n",
    "    vec = np.array(Image.open(filename))\n",
    "    vec = imresize(vec,(224,224)).astype(np.float32)/255.0\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    vec = (vec-mean)/std\n",
    "    return vec\n",
    "    \n",
    "img_dir = '.'\n",
    "img_names = [x for x in os.listdir(img_dir) if 'jpeg' in x.lower()]\n",
    "imgs = [get_img(os.path.join(img_dir,x)) for x in img_names]\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "scores = sess.run(classifier,feed_dict={input_image:np.array(imgs).reshape([-1,224,224,3])})\n",
    "for idx,s in enumerate(np.argmax(scores,1)):\n",
    "    print(img_names[idx],labels[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save(sess, 'squeezenet.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "input_data = torch.FloatTensor(np.transpose(np.array(imgs),[0,3,1,2]))\n",
    "model.eval()\n",
    "pyt_scores = model(Variable(input_data))\n",
    "scores_ref = pyt_scores.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_error(x, y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "print(rel_error(scores,scores_ref))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
